
import os
from formatting import *
from experiment import *
from parse_experiments import *
import random
root = os.environ["SCARAB_ROOT"]

# Arguments are unkmap, test, outmapping, bigdata
def build_experiment(source, target, env, for_signature=False):
     """ 1) .unkmap for corpus
         2) original test file
         3) constraint description file
         out -> new test file (with extra sentences)
     """
     command = ""
     if env["ADD_SENTENCES"]:
          command = "python $SCARAB_PY/build_experiment.py %s %s %s $NUM_SENT %s > %s;"%(source[0],
                                                                                      source[1],
                                                                                      source[2],
                                                                                      target[2],
                                                                                      target[0])
     else:
          command = "cp %s %s;" % (source[1],
                                   target[0])
          
     return command + "wc -l %s | awk '{print $1-1}' > %s" %(target[0],  target[1])

def build_experiment_emit(source, target, env, for_signature=False):
     #source.append('$SCARAB_PY/build_experiment.py')
     #target.append(target[0] + "_desc")
     return target, source


def build_experiment_multi(source, target, env, for_signature=False):
     command = "python $SCARAB_PY/build_experiment_multi.py --wordcount %s --test %s  --numtake $NUM_SENT --desc %s --language $LANGUAGE > %s;"%\
     (source[0],
      source[1],
      #source[2],
      target[2],
      target[0])
          
     return command + "wc -l %s | awk '{print $1-1}' > %s" %(target[0],  target[1])


def unknown_list(source, target, env, for_signature=False):
     return "awk '{print $2}' %s | grep -v '^$' > %s " %(source[0], target[0])

def train_unknown(source, target, env, for_signature=False):
     return "python $SCARAB_PY/unknown_words.py $UNK_THRES %s < %s"%(target[0], source[0])

def train_unknown_emit(source, target, env):
     source.append('$SCARAB_PY/unknown_words.py')
     return target, source

def viterbi(source, target, env, for_signature=False):
     """
     hypergraph test prefix
     sent description
     """
     return '$SCARAB_ROOT/run_tagger $SCARAB_ROOT/parse/config.ini %s 0 `cat %s`| tee %s' \
                           % (source[0], source[1], target[0])

def viterbi_emit(source, target, env):
     source.append('$SCARAB_PY/run_tagger')
     return target, source

def MakeGold(source, target, env, for_signature=False):
     return "head -n $NUM_SENT %s > %s"%(source[0], target[0])
     
def ctag_convert(source, target, env, for_signature=False):
     return 'grep SENT %s | python $SCARAB_PY/map/unmap_pos.py --language $LANGUAGE %s  > %s' % (source[0], source[1],  target[0])


def stanford_train(source, target, env, for_signature=False):
     return "cd $SCARAB_ROOT/third-party/stanford-postagger-2009-12-24/;java -Xmx1g -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -prop %s  -trainFile %s -model %s"%(source[0], source[1], target[0])


def crf_run(source, target, env, for_signature=False):
     return 'java -Xmx1g -cp $SCARAB_ROOT/third-party/CRFTagger/crftagger.jar crf.tagger.CRFTagger -modeldir ../../CRFTagger/model -inputfile %s  -unknownwords %s > %s' % (source[0], source[1], target[0])


def crf_run_emit(source, target, env):
     source.append('$SCARAB_ROOT/third-party/CRFTagger/crftagger.jar')
     return target, source

def stanford_tagger_run(source, target, env, for_signature=False):
     return 'cd $SCARAB_ROOT/third-party/stanford-postagger-2009-12-24/; ./stanford-postagger.sh %s %s > %s'%(source[0], source[1],  target[0])

#return 'java -Xmx1g -cp $SCARAB_ROOT/third-party/CRFTagger/crftagger.jar crf.tagger.CRFTagger -modeldir ../../CRFTagger/model -inputfile %s  -unknownwords %s > %s' % (source[0], source[1], target[0])





def hypergraph_run(source, target, env, for_signature=False):
     tmp = "$SCARAB_ROOT/tmp/lattice.%s"%hash(str(source[0]))
     return ['grep LATTICE %s > %s'%(source[0], tmp), 
             "$SCARAB_ROOT/hypergraph/convert %s %s"%(target[0], tmp),
             "touch %s"%(target[0]),
             "rm %s" %tmp]

def hypergraph_run_emit(source, target, env):
     source.append('$SCARAB_ROOT/hypergraph/convert')
     return target, source



def eval_run(source, target, env, for_signature=False):
     return "python $SCARAB_PY/eval/pos_accuracy.py %s %s | tee %s"%(source[0], source[1], target[0])

def eval_run_emit(source, target, env):
     source.append('$SCARAB_PY/eval/pos_accuracy.py')
     return target, source

def full_lp(source, target, env, for_signature=False):

     return '$SCARAB_ROOT/run_potts_tagger $SCARAB_ROOT/parse/config.ini %s %s 0 `cat %s` 0 `cat %s` $PENALTY %s | tee %s' % (source[0], source[2], source[1], source[4], source[3], target[0]) 

def full_lp_emit(source, target, env):
     source.append('$SCARAB_ROOT/run_potts_tagger')
     return target, source


def marginals(source, target, env, for_signature=False):
     return '$SCARAB_ROOT/marginals $SCARAB_ROOT/parse/config.neg.ini %s 0 $END_INDEX > %s' % (source[0], target[0]) 

def marginals_emit(source, target, env):
     source.append('$SCARAB_ROOT/marginals')
     return target, source


def decomp(source, target, env, for_signature=False):
     return '$SCARAB_ROOT/run_decomp_tagger $SCARAB_ROOT/parse/config.ini %s  0 `cat %s` %s 0 `cat %s` %s | tee %s' \
            % (source[0],  source[1], source[2], source[4], source[3], target[0])

# def decomp(source, target, env, for_signature=False):
#      return '$SCARAB_ROOT/run_decomp_tagger $SCARAB_ROOT/parse/config.ini %s 0 $END_INDEX %s $PENALTY | tee %s' % (source[0], source[1], target[0]) 


def decomp_emit(source, target, env):
     source.append('$SCARAB_ROOT/run_decomp_tagger')
     return target, source

def pos_cons_old_build(source, target, env, for_signature=False):
     return 'python $SCARAB_PY/pos_constraints.py %s %s > %s' % (source[0], source[1], target[0]) 

def pos_cons_old_emit(source, target, env):
     source.append('$SCARAB_PY/pos_constraints.py')
     return target, source


def pos_cons_build(source, target, env, for_signature=False):
     tmp = "$SCARAB_ROOT/tmp/beam.%s"%(hash(str(source[2])))
     return ['grep BEAM %s > %s'%(source[2], tmp),
             'python $SCARAB_PY/pos_constraints_mrf2.py --language $LANGUAGE %s %s %s $CONST_TYPE %s $PENALTY %s %s $NUM_SENT %s > %s'
               % (source[0], source[1], target[0], source[3], target[2], tmp, source[4], target[1]) ,
             "rm %s"%tmp]
             

def pos_cons_emit(source, target, env):
     source.append('$SCARAB_PY/pos_constraints_mrf2.py')
     #target.append(target[1] + "_desc")
     return target, source


def full_diff(source, target, env, for_signature=False):
     return 'python triple_diff.py %s %s %s > %s' % (source[0], source[1], source[2], target[0]) 

def error_analysis(source, target, env, for_signature=False):
     return 'python $SCARAB_PY/error_analysis.py --language $LANGUAGE %s %s %s %s %s %s  | tee %s' % tuple(source[:6] + [target[0]]) 

def error_analysis_emit(source, target, env):
     source.append('$SCARAB_PY/error_analysis.py')
     return target, source
     
def PrettyPosComp(source, target, env, for_signature=False):
     tmp = "$SCARAB_ROOT/tmp/constraints.%s"%hash(str(source[0]))
     return ["grep CONSTRAINT %s > %s"%(source[0], tmp),
             "python $SCARAB_PY/eval/pos_comp_eval.py --num_gold $NUM_SENT --language $LANGUAGE %s %s %s %s  > %s"%(source[1], source[2], source[3], tmp,target[0]),
             "rm %s"%tmp]

builders = {
     "BuildExperiment":
     Builder(generator = build_experiment,
             emit = build_experiment_emit
             ),

     "BuildExperimentMulti":
     Builder(generator = build_experiment_multi),


     "Viterbi": Builder(generator = viterbi,
                      suffix='.ctagging',
                      emit = viterbi_emit
                      ),

     "FullLP": Builder(generator =full_lp, 
                      suffix= '.ctagging',
                       emit = full_lp_emit),

     "Marginals": Builder(generator =marginals, 
                       emit = marginals_emit),

     "DecompTag": Builder(generator =decomp, 
                      suffix= '.ctagging',
                          emit = decomp_emit),


     "ToTag": Builder(generator = ctag_convert,
                      suffix='.tagging'
                      
                      ),

     "CRFTagger": Builder(generator = crf_run,
                          suffix='.crf',
                          emit = crf_run_emit),

     "TrainStanfordTagger": Builder(generator = stanford_train),

     "StanfordTagger": Builder(generator = stanford_tagger_run,
                          suffix='.crf'),

     "CreateHypergraph": Builder(generator = hypergraph_run,
                                 emit = hypergraph_run_emit),

     "Eval": Builder(generator = eval_run,
                   suffix='.eval'),

     "Flatten":Builder(action =SimpleToFlat(), 
                       suffix= '.flattagging',
                       src_suffix='.tagging'),
     
     "BuildConstraint": Builder(generator = pos_cons_build, emitter= pos_cons_emit),

     "BuildConstraintOld": Builder(generator = pos_cons_old_build, emitter= pos_cons_old_emit),

     "UnknownList": Builder(generator = unknown_list, 
                            src_suffix=".constraints", suffix='.unknown'),

     "TrainUnknown": Builder(generator = train_unknown, suffix='.unkmap', emitter= train_unknown_emit),

     "FullDiff": Builder(generator = full_diff, suffix='.tagdiff'),
     
     "ErrorAnalysis": Builder(generator = error_analysis, suffix='.taganal', emitter=error_analysis_emit),

     "MakeGold": Builder(generator = MakeGold, src_suffix='.gold', suffix='.tagging'),
     "PrettyPosComp": Builder(generator = PrettyPosComp)
     }



env = Environment(ENV=os.environ)
env.Append(BUILDERS= builders)
root = os.environ["SCARAB_ROOT"]

env.Append(SCARAB_ROOT = root)
env.Append(SCARAB_PY = root + "/data_management/")
env.Append(SCARAB_RESULTS = root + "/experiments/results/")
env.Append(SCARAB_DATA = root + "/parse/data/")
env.Append(SCARAB_TMP = root + "/tmp/")
env.Append(CONLL_FILES ="/data/nlp4/srush/mikedata/roi/nips/")

def register_experiment(env, exp):

     unk_map = env.TrainUnknown(exp.unknown_words(), exp.train_file(),
                                UNK_THRES = exp.unk_thres)

#      test_sents, corpus_desc, build_constraint_file = \
#                  env.BuildExperimentMulti((exp.full_test_file(), exp.full_test_file_desc(), exp.build_constraint_file()),
#                                      (unk_map,  exp.original_test_file(), exp.brown_clusters()),
                      
#                                      NUM_SENT = exp.num_sent(),
#                                      LANGUAGE = exp.language,
#                                      ADD_SENTENCES = exp.add_sent())

     test_sents, corpus_desc, build_constraint_file = \
                 env.BuildExperiment((exp.full_test_file(), exp.full_test_file_desc(), exp.build_constraint_file()),
                                     (unk_map,  exp.original_test_file(), exp.brown_clusters()),
                      
                                     NUM_SENT = exp.num_sent(),
                                     LANGUAGE = exp.language,
                                     ADD_SENTENCES = exp.add_sent())


     constraints = env.BuildConstraintOld(exp.constraint_old_prefix(),
                                          (unk_map, test_sents))
     
     unk_list = env.UnknownList(exp.unknown_prefix(), 
                                constraints)

     temp_tags = env.StanfordTagger(exp.temporary_tags(), 
                                    (exp.tagger_model(), test_sents))


     lattice_hypergraphs = env.CreateHypergraph(exp.lattice_prefix(),
                                                temp_tags)

     marginals = exp.temporary_margs()
     marginals = env.Command(exp.temporary_margs(), (), "touch %s"%(marginals))

     constraints_mrf, mrf_link, mrf_link_desc = \
         env.BuildConstraint( (exp.constraint_mrf_prefix(), 
                               exp.mrf_link_prefix(), exp.mrf_link_prefix_desc()),
                              (unk_map, test_sents, temp_tags, exp.train_file()+".pos", build_constraint_file), 
                              CONST_TYPE=exp.constraint_type(),
                              PENALTY = exp.penalty(),
                              NUM_SENT = exp.num_sent(),
                              LANGUAGE = exp.language
                              )

     decoders = {}
     decoders['viterbi'] =env.Viterbi( exp.result_prefix()+"_viterbi", 
                                       (lattice_hypergraphs, corpus_desc) 
                                       )

     decoders['lp']= env.FullLP( exp.result_prefix() + "_lp", 
                                 (lattice_hypergraphs, corpus_desc, constraints_mrf, mrf_link, mrf_link_desc),                                 
                                 PENALTY = exp.penalty())

     decoders['decomp']= env.DecompTag( exp.result_prefix() + "_decomp", 
                                      (lattice_hypergraphs, corpus_desc, constraints_mrf, mrf_link, mrf_link_desc),                                 
                                      PENALTY = exp.penalty())
     gold = env.MakeGold(exp.gold_file(), exp.gold_file(), NUM_SENT = exp.num_sent())

     flats = {}
     for dec_type,result in decoders.iteritems():
          tagging_name = "%s_%s"%(exp.result_prefix(), dec_type)
          
          tagging = env.ToTag( tagging_name, 
                     (result,
                      test_sents), LANGUAGE = exp.language)

          env.Eval( tagging_name, 
                    (tagging,
                     gold))

          flats[dec_type] = env.Flatten( tagging_name, tagging)

     flats['gold'] = env.Flatten( "%s_%s"%(exp.result_prefix(), "gold"), 
                                  gold)
       
     
     env.FullDiff(exp.result_prefix(), 
          (flats["viterbi"], flats['lp'], flats["gold"])
                  )

     env.ErrorAnalysis(exp.result_prefix(), 
                       ( flats["gold"], unk_map, marginals, flats["viterbi"], flats['lp'], flats["gold"]),
                       LANGUAGE = exp.language)

     a= env.ErrorAnalysis(exp.result_prefix()+"_d", 
                       ( flats["gold"], unk_map, marginals, flats["viterbi"], flats['decomp'], flats["gold"]),
                          LANGUAGE = exp.language
                       )

     b = env.PrettyPosComp(exp.result_prefix()+ "_d.pretty", 
                       (decoders["decomp"], flats["viterbi"], flats['decomp'], exp.gold_file() +".gold"),
                           NUM_SENT = exp.num_sent(),
                           LANGUAGE = exp.language)
     return (a,b)
def parser_run(source, target, env, for_signature=False):
     """
     0 - the model
     1 - the test file
     target - parses
     """
     return "cd $SCARAB_ROOT/third-party/mstparser/;java -classpath \".:lib/trove.jar\" -Xmx1800m mstparser.DependencyParser test model-name:%s  test test-file:%s > %s"%(source[0], source[1], target[0])

def parser_run_emit(source, target, env, for_signature=False):
     #source.append('$SCARAB_ROOT/third-party/mstparser/mstparser.jar')
     return target, source

def parser_run_so(source, target, env, for_signature=False):
     """
     0 - the model
     1 - the test file
     target - parses
     """
     return "cd $SCARAB_ROOT/third-party/mstparser/;java -classpath \".:lib/trove.jar\" -Xmx1800m mstparser.DependencyParser order:2 test model-name:%s  test test-file:%s | grep \"\\(PROB\\|DONE\\)\" > %s"%(source[0], source[1], target[0])

def parser_run_emit_so(source, target, env, for_signature=False):
     #source.append('$SCARAB_ROOT/third-party/mstparser/mstparser.jar')
     return target, source


def parser_to_hypergraph(source, target, env, for_signature=False):
     tmp = "$SCARAB_ROOT/tmp/parse.%s"%hash(str(source[0]))
     return ";".join(["cat %s | grep \"\\(PROB\\|DONE\\)\" > %s"%(source[0], tmp),
                      "cat %s | $SCARAB_ROOT/parse/convert %s | tee %s"%(tmp, target[0], target[1]),
                      "touch %s"%(target[0]),
                      "rm %s"%tmp])

def parser_to_hypergraph_emit(source, target, env, for_signature=False):
     source.append('$SCARAB_ROOT/parse/convert')
     return target, source

def parser_to_hypergraph_so(source, target, env, for_signature=False):
     tmp = "$SCARAB_ROOT/tmp/parse.%s"%hash(str(source[0]))
     return ";".join(["cat %s | grep \"\\(PROB\\|DONE\\)\" > %s"%(source[0], tmp),
                 "cat %s | $SCARAB_ROOT/parse/convert_SO %s | tee %s"%(tmp,target[0], target[1]),
                 "touch %s"%(target[0]),
                 "rm %s"%tmp])

def parser_to_hypergraph_emit_so(source, target, env, for_signature=False):
     source.append('$SCARAB_ROOT/parse/convert_SO')
     return target, source



def viterbi_parse(source, target, env, for_signature=False):
     """
     hypergraph test prefix
     sent description
     """
     return '$SCARAB_ROOT/run_parser --feature_weights_file $SCARAB_ROOT/parse/config.ini --parse_file %s | tee %s' \
                           % (source[0], target[0])

def viterbi_parse_emit(source, target, env):
     source.append('$SCARAB_PY/run_parser')
     return target, source

def DualDecompParse(source, target, env, for_signature=False):
     return (('$SCARAB_ROOT/run_decomp_parser '+
             '--feature_weights_file $SCARAB_ROOT/parse/config.ini ' +
             '--parse_file %s ' +
             '--mrf_file_prefix %s --mrf_start 0 --mrf_end `cat %s` '+
             '--alignment_file %s | tee %s')%
             (source[0],  #source[1],
              source[1], source[3], source[2], target[0]))


def DualDecompParse_emit(source, target, env):
     source.append('$SCARAB_PY/run_decomp_parser')
     return target, source

def full_lp_parse(source, target, env, for_signature=False):
     """
     hypergraph test prefix
     sent description
     """
     return '$SCARAB_ROOT/run_full_parser $SCARAB_ROOT/parse/config.ini %s  0 `cat %s` %s 0 `cat %s` %s | tee %s' \
                           % (source[0],  source[1], source[2], source[4], source[3], target[0])

def full_lp_parse_emit(source, target, env):
     source.append('$SCARAB_PY/run_full_parser')
     return target, source

def to_parse(source, target, env, for_signature=False):
     """
     """
     return 'grep SENT %s | python $SCARAB_PY/map/unmap_sent.py %s $SCARAB_PY/map/%s.map > %s'%(source[0], source[1],  env['LANGUAGE'], target[0])


def to_parse_emit(source, target, env):
     return target, source

def build_parse_constraints(source, target, env, for_signature=False):
     """
     """
     return 'python $SCARAB_PY/parse_constraints_mrf.py %s $PENALTY %s %s %s %s | tee %s'%(source[0], source[1], source[2],  target[0], target[2], target[1])

def build_parse_constraints_emit(source, target, env):
     source.append('$SCARAB_PY/parse_constraints_mrf.py')
     return target, source

def build_parse_constraints_multi(source, target, env, for_signature=False):
     """
     """
     
     return 'python $SCARAB_PY/parse_constraints_mrf_multi_fixed.py  --test %s --penalty $PENALTY --train %s --linkdesc %s --constraints %s --language $LANGUAGE | tee %s'\
            %(source[0], source[2],  target[0], target[2], target[1])

def build_parse_constraints_multi_emit(source, target, env):
     return target, source + [env['SCARAB_PY'] + '/parse_constraints_mrf_multi_fixed.py']


def ParseComparison(source, target, env, for_signature=False):
     tmp = "$SCARAB_ROOT/tmp/parse_diff.%s"%(abs(hash((str(source[0]), str(source[1])))))
     return ";".join(["sdiff -w 20 %s %s > %s"%(source[0],source[1], tmp),
             "paste %s %s > %s"%(tmp, source[2], target[0]),
             "rm %s"%(tmp)])

def ParseComparison_emit(source, target, env, for_signature=False):
     return target, source

def PrettyComp(source, target, env, for_signature=False):
     tmp = "$SCARAB_ROOT/tmp/constraints.%s"%hash(str(source[0]))
     return ["grep CONSTRAINT %s > %s"%(source[0], tmp),
             "python $SCARAB_PY/eval/dep_comp_eval.py --language $LANGUAGE %s %s %s %s  > %s"%(source[1], source[2], source[3], tmp, target[0]),
             "rm %s"%(tmp)]

def PrettyComp_emit(source, target, env, for_signature=False):
     return target, source

def TrainParse(source, target, env, for_signature=False):
     return 'cd $SCARAB_ROOT/third-party/mstparser/;java -Djava.io.tmpdir="/afs/csail.mit.edu/u/s/srush/h/Projects/relax-decode/tmp" -classpath \".:lib/trove.jar\" -Xmx4g mstparser.DependencyParser  train model-name:%s  train-file:%s '%(target[0], source[0])

def SplitTraining(source, target, env, for_signature=False):
     return 'python $SCARAB_PY/take_random.py $NUM $RAND %s %s %s'%(source[0], target[0], target[1])

builders = {
     "TrainParse":
     Builder(generator = TrainParse),

     "SplitTraining":
     Builder(generator = SplitTraining),

     "Parse":
     Builder(generator = parser_run,
             emit = parser_run_emit),
     "ParseToHypergraph":
     Builder(generator = parser_to_hypergraph,
             emit = parser_to_hypergraph_emit),
     "ParseSO":
     Builder(generator = parser_run_so,
             emit = parser_run_emit_so),
     "ParseToHypergraphSO":
     Builder(generator = parser_to_hypergraph_so,
             emit = parser_to_hypergraph_emit_so),

     "ViterbiParse":
     Builder(generator = viterbi_parse,
             emit = viterbi_parse_emit),
     "FullLPParse":
     Builder(generator = full_lp_parse,
             emit = full_lp_parse_emit),
     "DualDecompParse":
     Builder(generator = DualDecompParse,
             emit = DualDecompParse_emit),

     "ToParse":
     Builder(generator = to_parse,
             emit = to_parse_emit, suffix=".parse"),
     "BuildParseConstraints":
     Builder(generator = build_parse_constraints,
             emit = build_parse_constraints_emit),

     "BuildParseConstraintsMulti":
     Builder(generator = build_parse_constraints_multi,
             emit = build_parse_constraints_multi_emit),
     "ParseComparison":
     Builder(generator = ParseComparison,
             emit = ParseComparison_emit,
             suffix = ".comp"),
     "PrettyComparison":
     Builder(generator = PrettyComp,
             emit = PrettyComp_emit)

     }

env.Append(BUILDERS= builders)

def register_cross_val(env, exp):
     models = []
     for i in range(10):
          (local_test, local_train) = env.SplitTraining(("$SCARAB_DATA/tmp_test_%s"%i, "$SCARAB_DATA/tmp_train_%s"%i ),
                                                        exp.training_file(), RAND = i, NUM=10)
          model = env.TrainParse("$SCARAB_ROOT/third-party/mstparser/tmp_model_%s"%i, local_train)

          local_experiment = ParseExperiment(original_test= str(local_test).split('/')[-1],
                                             prefix ="val_%s_%s"%(exp.prefix,i),
                                             gold_file = str(local_test).split('/')[-1],
                                             mrf_spec = "parse_constraints_big",
                                             penalty = exp.penalty(),
                                             model = str(model[0]).split('/')[-1],
                                             training = str(local_train).split('/')[-1])
          models.append(register_parse_experiment(env, local_experiment))

     return models

     
def register_parse_experiment(env, exp):
     parse_out = env.ParseSO(exp.parse_out(), (exp.model(), exp.test_file()))

#      hypergraphs, hypergraphs_desc = env.ParseToHypergraphSO(
#           (exp.hypergraph_prefix(), exp.hypergraph_prefix()+"_desc"),
#           parse_out)
     decoders = {}
     decoders['viterbi'] =env.ViterbiParse( exp.result_prefix()+"_viterbi", 
                                            (parse_out ))
     #hypergraphs, hypergraphs_desc))

     targ = (exp.constraint_mrf_prefix()+"_desc",
             exp.constraint_mrf_prefix()+"_link",
             exp.constraint_mrf_prefix())
     
     src =  ( exp.test_file(), exp.mrf_spec(), exp.training_file() )
     
     constraints_desc, mrf_link, constraints = env.BuildParseConstraintsMulti( targ,src,
                                                                               PENALTY=exp.penalty(),
                                                                               LANGUAGE=exp.language)
           


#      decoders['lp']= env.FullLPParse( exp.result_prefix() + "_lp", 
#                                       (parse_out,
#                                        #hypergraphs, hypergraphs_desc,
#                                        constraints, mrf_link, constraints_desc),                                 
#                                       PENALTY = exp.penalty())

     decoders['decomp']= env.DualDecompParse( exp.result_prefix() + "_decomp", 
                                      (parse_out, #hypergraphs, hypergraphs_desc,
                                       constraints, mrf_link, constraints_desc),                                 
                                      PENALTY = exp.penalty())


     #print decoders['decomp']
     flats = {}
     for dec_type,result in decoders.iteritems():
          parse_name = "%s_%s"%(exp.result_prefix(), dec_type)
          
          flats[dec_type] = env.ToParse( parse_name, 
                                         (result,exp.test_file()),
                                         LANGUAGE = exp.language)

          #env.Eval( tagging_name, 
          #          (tagging,
          #           exp.gold_file()))

          #flats[dec_type] = env.Flatten( tagging_name, tagging)

     #flats['gold'] = env.Flatten( "%s_%s"%(exp.result_prefix(), "gold"), 
     #                             exp.gold_file())
       
          
#      env.ParseComparison(exp.result_prefix(), 
#           (flats["viterbi"], flats['lp'], exp.test_file())
#                          )

     a = env.ParseComparison(exp.result_prefix()+ "_d", 
                         (flats["viterbi"], flats['decomp'], exp.test_file())
                         )

     b = env.PrettyComparison(exp.result_prefix()+ "_d.pretty", 
          (decoders["decomp"], flats["viterbi"], flats['decomp'], exp.test_file()), LANGUAGE=exp.language)

     #env.ErrorAnalysis(exp.result_prefix(), 
     #                  ( flats["gold"], unk_map, marginals, flats["viterbi"], flats['lp'], flats["gold"])
     #                  )

     return (b,)

# all = ()
# for i in range(50, 482):
#      all += register_experiment(env, dev_experiment_100(i))
# env.Alias( "dev_experiment", all)

# all = ()
# for i in range(20):
#      all += register_experiment(env, dev_experiment_100_lower(i))
# env.Alias( "dev_experiment_lower", all)

# all2 = ()
# for i in range(482):
#      all2 += register_experiment(env, test_experiment(i, size=100))
# env.Alias( "test_experiment_100", all2)

all2 = ()
for i in range(482):
     all2 += register_experiment(env, test_experiment(i, size=500))
env.Alias( "test_experiment_500", all2)


# for i in range(30, 50):
#      all += register_experiment(env, dev_experiment(i))
# env.Alias( "dev_experiment2", all)

# for i in range(50, 75):
#      all += register_experiment(env, dev_experiment(i))
# env.Alias( "dev_experiment3", all)


# all = ()
# for i in range(75, 100):
#      all += register_experiment(env, dev_experiment(i))
# env.Alias( "dev_experiment4", all)


# all = ()
# for i in range(75, 125):
#      all += register_experiment(env, dev_experiment(i))
# env.Alias( "dev_experiment3", all)

# all = ()
# for i in range(125, 200):
#      all += register_experiment(env, dev_experiment(i))
# env.Alias( "dev_experiment4", all)

env.Alias("pos_german", register_experiment(env,german_exp))



register_parse_experiment(env, parse_experiment_strong_mi_asymlow_tiny)
# register_parse_experiment(env, parse_experiment_strong_mi_asymlow_tiny2)

# all = ()
# for i in range(12):
#      all += register_parse_experiment(env, parse_dev_experiment(i))
# env.Alias( "parse_dev_experiment", all)

all = ()
for i in range(1, 12):
     all += register_parse_experiment(env, parse_dev_experiment_size(i,50, "full", 0.7))
env.Alias( "parse_dev_experiment2", all)


# all = ()
# for i in range(12):
#      all += register_parse_experiment(env, parse_dev_experiment_size(i,500, "full", 0.3))
# env.Alias( "parse_dev_experiment3", all)


# all = register_cross_val(env, parse_dev_experiment_size(1,100, "", 0.3))
# env.Alias( "parse_cross_val", all)

all = register_parse_experiment(env, parse_dev_experiment_size(1,50))
env.Alias( "parse_dev_full_experiment", all)

all = register_parse_experiment(env, parse_dev_experiment_size(1,100))
env.Alias( "parse_dev_size", all)

all = register_parse_experiment(env, parse_dev_experiment_size(1,50, "pre", 0.7))
env.Alias( "parse_dev_size_5", all)

all = register_parse_experiment(env, parse_dev_experiment_size(1,500, "pre", 0.3))
env.Alias( "parse_dev_size_6", all)

# all = register_parse_experiment(env, parse_dev_experiment_size(3,100, "pre", 0.3))
# env.Alias( "parse_dev_size_7", all)

# all = register_parse_experiment(env, parse_dev_experiment_size(3,500, "pre", 0.7))
# env.Alias( "parse_dev_size_8", all)


# all = register_parse_experiment(env, parse_dev_experiment_size(1,50))
# env.Alias( "parse_dev_size2", all)

# all = register_parse_experiment(env, parse_dev_experiment_size(1,500))
# env.Alias( "parse_dev_size3", all)

# all = register_parse_experiment(env, simple_parse)
# env.Alias( "parse_simple", all)





# all = ()
# for i in range(23):
#      all += register_parse_experiment(env, parse_test_experiment(i))
# env.Alias( "parse_test_experiment", all)

# all = ()
# for i in range(23):
#      all += register_parse_experiment(env, parse_test_experiment(i, modelsize=100, penalty =0.3))
# env.Alias( "parse_test_experiment_100", all)

# all = ()
# for i in range(23):
#      all += register_parse_experiment(env, parse_test_experiment(i, modelsize=200, penalty =0.3))
# env.Alias( "parse_test_experiment_200", all)

# all = ()
# for i in range(23):
#      all += register_parse_experiment(env, parse_test_experiment(i, modelsize=500, penalty =0.3))
# env.Alias( "parse_test_experiment_500", all)



# SETUP FOR PARSING EXPERIMENTS

def setup_parsing_experiment(env, language, size = 50):
     all = ()
     src = ("$CONLL_FILES/%s_pos_punc"%language,
            "$CONLL_FILES/%s_direction"%language)
     targ = ("$SCARAB_ROOT/data_management/map/%s.conf"%language,)
     all += env.Command(targ, src,"python $CONLL_FILES/extract.py %s %s > %s "%(src + targ))
     

     src = ("$CONLL_FILES/%s.train.gz"%language,)
     targ= ("$SCARAB_ROOT/third-party/mstparser/data/%s_%s"%(language,size),)
     all +=  env.Command(targ, src,
                 "zcat %s  | python $SCARAB_PY/remove_labels.py | python $SCARAB_PY/take_chunks.py %s - > %s"%(src + (size,)+ targ))


     src= ("$SCARAB_ROOT/third-party/mstparser/data/%s_%s"%(language,size),)
     targ= ("$SCARAB_DATA/%s_%s"%(language,size),)

     all +=  env.Command(targ, src,
                         "cp %s %s"%(src + targ))

     src= ("$SCARAB_ROOT/third-party/mstparser/data/%s_%s"%(language,size),)
     all += env.TrainParse(("$SCARAB_ROOT/third-party/mstparser/%s_%s.model"%(language,size),), src)
     
     src = ("$CONLL_FILES/%s_pos_list"%language,)
     targ= ("$SCARAB_ROOT/data_management/map/%s.map"%language,)
     all += env.Command(targ, src, "python $CONLL_FILES/add_extra.py < %s > %s"%(src + targ))


     all_dev = "$SCARAB_DATA/%s_parse_dev"%language
     src = ("$CONLL_FILES/%s.train.gz"%language,)
     targ= (all_dev,)
     all += env.Command(targ, src, "zcat %s |  python $SCARAB_PY/remove_labels.py | python $SCARAB_PY/drop_chunks.py 500 - | python $SCARAB_PY/take_chunks.py 500 - > %s"%(src + targ))

     dev_data = "$SCARAB_DATA/parse_dev_%s"%language
     Mkdir(dev_data)

     #src = ("$CONLL_FILES/%s.train.gz"%language,)
     src = (all_dev,)
     targ= tuple([dev_data + "/dev_%03d"%i for i in range(1)])

     all += env.Command(targ, src, "cd "+dev_data+"; cat %s | python $SCARAB_PY/chunk_parse.py 500 dev \"\" "%src)


     # TEST
     all_test = "$SCARAB_DATA/%s_parse_test"%language
     src = ("$CONLL_FILES/%s.test.gz"%language,)
     targ= (all_test,)
     all += env.Command(targ, src, "zcat %s |  python $SCARAB_PY/remove_labels.py > %s"%(src + targ))

     test_data = "$SCARAB_DATA/parse_test_%s"%language
     Mkdir(test_data)

     src = (all_test,)
     targ= tuple([test_data + "/test_%03d"%i for i in range(1)])

     all += env.Command(targ, src, "cd "+test_data+"; cat %s | python $SCARAB_PY/chunk_parse.py 10000 test \"\" "%src)

     all_test = "$SCARAB_DATA/%s_parse_test_ext"%language
     src = ("$CONLL_FILES/%s_extended_test.gz"%language,)
     targ= (all_test,)
     all += env.Command(targ, src, "zcat %s |  python $SCARAB_PY/remove_labels.py > %s"%(src + targ))

     test_data = "$SCARAB_DATA/parse_test_%s_ext"%language
     Mkdir(test_data)

     src = (all_test,)
     targ= tuple([test_data + "/test_%03d"%i for i in range(1)])

     all += env.Command(targ, src, "cd "+test_data+"; cat %s | python $SCARAB_PY/chunk_parse.py 10000 test \"\" "%src)

     return all



def setup_big_experiment(env, language, skip , size):
     all = []
     all_dev = "$SCARAB_DATA/%s_parse_big_dev"%language
     src = ("$CONLL_FILES/%s.train.gz"%language,)
     targ= (all_dev,)
     all += env.Command(targ, src, "zcat %s |  python $SCARAB_PY/remove_labels.py | python $SCARAB_PY/drop_chunks.py %s - | python $SCARAB_PY/take_chunks.py %s - > %s"%(src + (skip, size) + targ))

     dev_data = "$SCARAB_DATA/parse_big_dev_%s"%language
     Mkdir(dev_data)

     src = (all_dev,)
     targ= tuple([dev_data + "/dev_%03d"%i for i in range(5)])

     all += env.Command(targ, src, "cd "+dev_data+"; cat %s | python $SCARAB_PY/chunk_parse.py 100 dev \"\" "%src)
     return all


lang = ('danish', 'german', 'spanish',  'bulgarian', 'japanese')
train_size = {
     'bulgarian' : 12823,
     'danish':   5190,
     'german':   39216,
     'japanese': 17044,
     'spanish' : 3306
     }

env.Alias("spanish_setup_3000", setup_parsing_experiment(env, 'spanish', size=3000))
env.Alias("spanish_setup_big_3000", setup_big_experiment(env, 'spanish', skip=3000, size=306))
all = []
for j in range(4):
     all += register_parse_experiment(env, parse_language_big(j, 'spanish', penalty =0.3, size=3000))
env.Alias("spanish_parse_3000", all)

env.Alias("bulgarian_setup_12000", setup_parsing_experiment(env, 'bulgarian', size=12000))
env.Alias("bulgarian_setup_big_12000", setup_big_experiment(env, 'bulgarian', skip=12000, size=800))
all = []
for j in range(8):
     all += register_parse_experiment(env, parse_language_big(j, 'bulgarian', penalty =0.3, size=12000))
env.Alias("bulgarian_parse_12000", all)


size = {'danish': 322,
        'german': 357,
        'spanish': 206,
        'bulgarian': 398,
        'japanese': 709}

extended_size = {
     'danish': 1342,
     'german': 1487,
     'spanish': 1044,
     'bulgarian': 1728,
     'japanese': 2840
     }
full  = [] 

# for l in lang:
#      setup = env.Alias("%s_setup_25"%l, setup_parsing_experiment(env, l, size=25) )
#      full += setup
#      all = []
#      for j in range(5):
#           all += register_parse_experiment(env, parse_language(j, l, penalty =0.7, size=25))
#      full += env.Alias("parse_%s_25"%l, all)
#      test = []
#      for j in range(int(size[l]/100) +1):
#           test += register_parse_experiment(env, test_parse_language(j, l, penalty =0.5, size=25))


for l in lang:
     full +=  env.Alias("%s_setup"%l, setup_parsing_experiment(env, l) )
     all = []
     for j in range(1):
          all += register_parse_experiment(env, parse_language(j, l, penalty =0.5))
     full += env.Alias("parse_%s"%l, all)
     test = []
     for j in range(int(size[l]/100) +1):
          test += register_parse_experiment(env, test_parse_language(j, l, penalty =0.5, size=50))
     env.Alias("parse_test_%s"%l, test)

     ext_test = []
     #for j in range(int(extended_size[l]/100) +1):
     ext_test += register_parse_experiment(env, test_parse_language(0, l, penalty =0.5, size=50, extended=True))
     env.Alias("parse_ext_test_%s"%l, ext_test)

all_test = []
all_ext_test = []
for l in lang:
     full += env.Alias("%s_setup_100"%l, setup_parsing_experiment(env, l, size=100) )
     all = []
     for j in range(5):
          all += register_parse_experiment(env, parse_language(j, l, penalty =0.3, size=100))
     full += env.Alias("parse_%s_100"%l, all)
     test = []
     for j in range(int(size[l]/100) +1):
          test += register_parse_experiment(env, test_parse_language(j, l, penalty =0.3, size=100))
     env.Alias("parse_test_%s_100"%l, test)
     all_test += test

     ext_test = []
     for j in range(int(extended_size[l]/100) +1):
          ext_test += register_parse_experiment(env, test_parse_language(j, l, penalty =0.3, size=100, extended=True))
     env.Alias("parse_ext_test_%s_100"%l, ext_test)
     all_ext_test += ext_test

env.Alias("parse_test_100", all_test)
env.Alias("parse_ext_test_100", all_ext_test)

all_test =[]
all_ext_test = []
for l in lang:
     full += env.Alias("%s_setup_200"%l, setup_parsing_experiment(env, l, size=200) )
     all = []
     for j in range(5):
          all += register_parse_experiment(env, parse_language(j, l, penalty =0.3, size=200))
     full += env.Alias("parse_%s_200"%l, all)
     test = []

     for j in range(int(size[l]/100) +1):
          test += register_parse_experiment(env, test_parse_language(j, l, penalty =0.3, size=200))
     env.Alias("parse_test_%s_200"%l, test)
     all_test += test

     ext_test = []
     for j in range(int(extended_size[l]/100) +1):
          ext_test += register_parse_experiment(env, test_parse_language(j, l, penalty =0.3, size=200, extended=True))
     env.Alias("parse_ext_test_%s_200"%l, ext_test)
     all_ext_test += ext_test

env.Alias("parse_test_200", all_test)
env.Alias("parse_ext_test_200", all_ext_test)

all_ext_test = []
for l in lang:
     full += env.Alias("%s_setup_500"%l, setup_parsing_experiment(env, l, size=500) )
     all = []
     for j in range(5):
          all += register_parse_experiment(env, parse_language(j, l, penalty =0.3, size=500))
     full += env.Alias("parse_%s_500"%l, all)
     test = []
     for j in range(int(size[l]/100) +1):
          test += register_parse_experiment(env, test_parse_language(j, l, penalty =0.3, size=500))
     env.Alias("parse_test_%s_500"%l, test)

     ext_test = []
     for j in range(int(extended_size[l]/100) +1):
          ext_test += register_parse_experiment(env, test_parse_language(j, l, penalty =0.3, size=500, extended=True))
     env.Alias("parse_ext_test_%s_500"%l, ext_test)
     all_ext_test += ext_test

env.Alias("parse_ext_test_500", all_ext_test)

#      for j in range(int(size[l]/100) +1):
#           test += register_parse_experiment(env, test_parse_language(j, l, penalty =0.3, size=500))
#      env.Alias("parse_test_%s_500"%l, test)
#      all_test += test
# env.Alias("parse_test_500", all_test)


# for l in lang:
#      full += env.Alias("%s_setup_2000"%l, setup_parsing_experiment(env, l, size=2000) )
#      all = []
#      for j in range(5):
#           all += register_parse_experiment(env, parse_language(j, l, penalty =0.3, size=2000))
#      full += env.Alias("parse_%s_2000"%l, all)


# # for l in lang:
# #      full += env.Alias("%s_setup_5000"%l, setup_parsing_experiment(env, l, size=5000) )
# #      all = []
# #      for j in range(5):
# #           all += register_parse_experiment(env, parse_language(j, l, penalty =0.3, size=5000))
# #      full += env.Alias("parse_%s_5000"%l, all)

# env.Alias("all_dev", full)

# SETUP FOR PARSING EXPERIMENTS

def setup_tagging_experiment(env, language):
     train = "$SCARAB_DATA/%s_gold_50.pos"%language
     model = "$SCARAB_ROOT/third-party/stanford-postagger-2009-12-24/models/%s_50.model"%language
     props = "$SCARAB_DATA/%s_50.props"%language
     all = ()
     src = ("$CONLL_FILES/%s.train.gz"%language,)
     targ = (train,)
     all += env.Command(targ, src,
                        "zcat  %s | python $SCARAB_PY/format/convert_to_simple_tag.py  _ | head -n 50 > %s "%(src + targ))

     targ = (props,)
     all += env.Command(targ, (),
                        "python $SCARAB_ROOT/third-party/stanford-postagger-2009-12-24/models/make_train.py %s > %s "%((language,) + targ))
     
          
     src = (props, train)
     targ= (model,)
     all +=  env.TrainStanfordTagger(targ, src)
     
     src = ("$CONLL_FILES/%s.train.gz"%language,)
     targ= ("$SCARAB_DATA/%s_dev_gold.gold"%language,)
     all += env.Command(targ, src, "zcat %s | python $SCARAB_PY/format/convert_to_simple_tag.py / | tail -n 100 > %s"%(src + targ))

     src = ("$CONLL_FILES/%s.train.gz"%language,)
     targ= ("$SCARAB_DATA/%s_dev"%language,)
     all += env.Command(targ, src, "zcat %s | python $SCARAB_PY/format/convert_to_simple.py | tail -n 100 > %s"%(src + targ))


     src = ("$CONLL_FILES/%s.train.gz"%language,)
     targ= ("$SCARAB_DATA/%s_gold_50"%language,)
     all +=  env.Command(targ, src,
                 "zcat %s  |  python $SCARAB_PY/take_chunks.py 50 - > %s"%(src + targ))

     
     return all

for l in ('german',):
     env.Alias("%s_pos_setup"%l, setup_tagging_experiment(env, l) )

#java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.GlobalHolder -model
#models/german_50.model                      
